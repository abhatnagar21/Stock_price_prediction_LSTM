import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Load the dataset
data = pd.read_csv('aac_us.csv')  # Replace 'your_stock_data.csv' with your dataset file

# Feature Engineering: Adding more features
data['Open-Close'] = data['Open'] - data['Close']
data['High-Low'] = data['High'] - data['Low']

# Select features for training
features = ['Close', 'Open-Close', 'High-Low', 'Volume']
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[features].values)

# Define the function to create sequences
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:(i + seq_length), :])
        y.append(data[i + seq_length, 0])  # Predicting 'Close' price
    return np.array(X), np.array(y)

# Define hyperparameters
sequence_length = 50
train_test_split = 0.8
num_epochs = 10
batch_size = 64

# Create sequences
X, y = create_sequences(scaled_data, sequence_length)

# Split data into train and test sets
split = int(train_test_split * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# Reshape data for LSTM
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))

# Build LSTM model
model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dropout(0.2),
    LSTM(units=50, return_sequences=False),
    Dropout(0.2),
    Dense(units=1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Use early stopping and model checkpoints
early_stop = EarlyStopping(monitor='val_loss', patience=10)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

# Train the model
history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, 
                    validation_split=0.2, callbacks=[early_stop, model_checkpoint], verbose=1)

# Load the best model
model.load_weights('best_model.h5')

# Evaluate the model
train_loss = model.evaluate(X_train, y_train, verbose=0)
test_loss = model.evaluate(X_test, y_test, verbose=0)
print(f'Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')

# Make predictions
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Inverse transform predictions
train_predictions = scaler.inverse_transform(np.concatenate([train_predictions, np.zeros((train_predictions.shape[0], scaled_data.shape[1] - 1))], axis=1))[:, 0]
test_predictions = scaler.inverse_transform(np.concatenate([test_predictions, np.zeros((test_predictions.shape[0], scaled_data.shape[1] - 1))], axis=1))[:, 0]

# Plot predictions vs actual
plt.plot(data['Date'][sequence_length:sequence_length+len(train_predictions)], data['Close'][sequence_length:sequence_length+len(train_predictions)], label='Actual (Train)')
plt.plot(data['Date'][sequence_length:sequence_length+len(train_predictions)], train_predictions, label='Predicted (Train)')
plt.plot(data['Date'][split+sequence_length:split+sequence_length+len(test_predictions)], data['Close'][split+sequence_length:split+sequence_length+len(test_predictions)], label='Actual (Test)')
plt.plot(data['Date'][split+sequence_length:split+sequence_length+len(test_predictions)], test_predictions, label='Predicted (Test)')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Stock Price Prediction using LSTM')
plt.legend()
plt.show()
